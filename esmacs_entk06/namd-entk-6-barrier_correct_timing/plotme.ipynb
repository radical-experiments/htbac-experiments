{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JumanaDakka/git/htbac-experiments/venv/lib/python2.7/site-packages/radical/utils/atfork/stdlib_fixer.py:63: UserWarning: logging module already imported before fixup.\n",
      "  warnings.warn('logging module already imported before fixup.')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from radical.entk import Profiler\n",
    "import radical.analytics as ra\n",
    "import radical.utils as ru\n",
    "import radical.pilot as rp\n",
    "\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entire list of pipeline values for which profiles are available\n",
    "\n",
    "pipelines_list = [16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate task uids\n",
    "\n",
    "def get_task_uids(num_pipelines):\n",
    "    \n",
    "    num_tasks = num_pipelines*7*1\n",
    "    task_uids = []\n",
    "    for t in range(num_tasks):\n",
    "        task_uids.append('radical.entk.task.%04d'%t)\n",
    "\n",
    "    return task_uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get information from all the entk profiles\n",
    "\n",
    "def get_entk_info(pipelines):\n",
    "    \n",
    "    p = Profiler(src = './{0}_replicas'.format(pipelines))\n",
    "    \n",
    "    task_uids = get_task_uids(pipelines)\n",
    "    \n",
    "    entk_dur = p.duration(task_uids, states=['SCHEDULING','DONE'])\n",
    "    \n",
    "    # Time taken in appmanager to rreq function call\n",
    "    entk_core_1 = p.duration('radical.entk.appmanager.0000', events=['create amgr obj', 'init rreq submission'])\n",
    "    \n",
    "    # Time taken to tear down appmanager\n",
    "    entk_core_2 = p.duration('radical.entk.appmanager.0000', events=['start termination', 'termination done'])\n",
    "    \n",
    "    # Time taken to create resource manager obj\n",
    "    entk_core_3 = p.duration('radical.entk.resource_manager.0000', events = ['create rmgr obj', 'rmgr obj created'])\n",
    "    \n",
    "    # Time taken to create and submit resource reservation\n",
    "    entk_core_4 = p.duration('radical.entk.resource_manager.0000', events = ['creating rreq', 'rreq submitted'])\n",
    "    \n",
    "    # Time taken to deallocate resource reservation\n",
    "    entk_core_5 = p.duration('radical.entk.resource_manager.0000', events = ['canceling resource allocation', 'resource allocation cancelled'])\n",
    "    \n",
    "    entk_core_dur = entk_core_1 + entk_core_2 + entk_core_3 \n",
    "    \n",
    "    #entk_total_dur = entk_dur_1 + entk_dur_2 + entk_core_dur\n",
    "    \n",
    "    return entk_dur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information from all the rp profile files and json file\n",
    "# returns 0,0 if no rp files are found\n",
    "\n",
    "def get_rp_info(pipelines):\n",
    "\n",
    "    json_files = glob.glob('./{0}_replicas/*.json'.format(pipelines))\n",
    "    print json_files\n",
    "    json_file = json_files[0]\n",
    "    json      = ru.read_json(json_file)\n",
    "    sid       = os.path.basename(json_file)[:-5]\n",
    "\n",
    "    session = ra.Session(sid, stype='radical.pilot', src='{0}_replicas/'.format(pipelines))\n",
    "    units = session.filter(etype='unit', inplace=False)\n",
    "\n",
    "    exec_dur = units.duration([rp.AGENT_EXECUTING, rp.AGENT_STAGING_OUTPUT_PENDING])\n",
    "    rp_dur = units.duration([rp.UMGR_SCHEDULING_PENDING, rp.DONE])\n",
    "    data_dur = units.duration([rp.UMGR_STAGING_INPUT, rp.AGENT_STAGING_INPUT_PENDING]) + units.duration([rp.AGENT_STAGING_INPUT, rp.AGENT_SCHEDULING_PENDING]) + units.duration([rp.AGENT_STAGING_OUTPUT, rp.UMGR_STAGING_OUTPUT_PENDING]) + units.duration([rp.UMGR_STAGING_OUTPUT, rp.DONE])\n",
    "\n",
    "    return exec_dur, rp_dur, data_dur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./16_replicas/rp.session.two.jdakka.017476.0003.json']\n",
      "3059.78859997 0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['EnTK overhead', 'RP overhead', 'Execution duration'])\n",
    "\n",
    "pipelines_list = [16]\n",
    "\n",
    "for pipelines in pipelines_list:\n",
    "    entk_dur = get_entk_info(pipelines)\n",
    "    exec_dur, rp_dur, data_dur = get_rp_info(pipelines)\n",
    "    \n",
    "    print entk_dur, rp_dur, exec_dur, data_dur\n",
    "    df.loc[pipelines] = [entk_dur - rp_dur, rp_dur - exec_dur, exec_dur]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Execution duration',axis=1)\n",
    "ax1 = df.plot(kind='bar', title='Time taken by EnTK and RP to execute a workflow consisting of \\n X Pipelines, 7 Stages per Pipeline and 1 Task per Stage on NCSA.BW (Task executable = \"ESMACS\", number of trials per data point = 1)')\n",
    "ax1.set_xlabel('Number of Pipelines')\n",
    "ax1.set_ylabel('Time Execution Duration (seconds)')\n",
    "\n",
    "FONTSIZE=12\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "fig.show()\n",
    "#fig.savefig('namd_worload_devel.pdf', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
